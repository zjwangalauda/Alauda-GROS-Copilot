import streamlit as st

from app_shared import get_agent, get_rag_system, _llm_cache_key, _emb_cache_key

st.markdown('<div class="main-title">ğŸ“š çµé›€äº‘å‡ºæµ·æ™ºåº“ AI åŠ©æ‰‹</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-title">åŸºäº RAG æ£€ç´¢å¢å¼ºæŠ€æœ¯ã€‚æ‚¨å¯ä»¥éšæ—¶è¯¢é—®å…³äºæœ¬åœ°åŒ–åˆè§„ã€å‡ºæµ·æˆ˜ç•¥æŒ‡å¯¼æ‰‹å†Œã€é›‡ä¸»å“ç‰Œæ²Ÿé€šè¯æœ¯ç­‰å†…å®¹ã€‚</div>', unsafe_allow_html=True)

agent = get_agent(_key=_llm_cache_key())
rag = get_rag_system(_key=_emb_cache_key())

with st.spinner("â³ æ­£åœ¨æŒ‚è½½æœ¬åœ°çŸ¥è¯†åº“ (PDF & åŠ¨æ€æ²‰æ·€åº“)..."):
    is_loaded = rag.load_and_index()

if not is_loaded:
    st.error("âŒ çŸ¥è¯†åº“å¼•æ“å¯åŠ¨å¤±è´¥ï¼Œæœªæ‰¾åˆ°å¯åŠ è½½çš„æ–‡æ¡£ã€‚")
else:
    if rag.embedding_mode == "vector":
        st.success("âœ… çŸ¥è¯†åº“å·²å°±ç»ª â€” **å‘é‡è¯­ä¹‰æœç´¢æ¨¡å¼**ï¼ˆå…¨ç²¾åº¦ï¼‰")
    else:
        st.warning(
            "âš ï¸ çŸ¥è¯†åº“å·²å°±ç»ªï¼Œä½†å½“å‰è¿è¡Œåœ¨**å…³é”®è¯é™çº§æ¨¡å¼**ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦æœªå¯ç”¨ï¼‰ã€‚\n\n"
            "å¦‚éœ€å¼€å¯å…¨ç²¾åº¦å‘é‡æ£€ç´¢ï¼Œè¯·åœ¨ `.env` ä¸­é…ç½®ï¼š\n"
            "```\nEMBEDDING_API_KEY=your_openai_compatible_key\n"
            "EMBEDDING_API_BASE=https://api.openai.com/v1\n```"
        )

chat_container = st.container()

if "messages" not in st.session_state:
    st.session_state.messages = []

with chat_container:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

if prompt := st.chat_input("æ‚¨å¯ä»¥å‘çŸ¥è¯†åº“æé—®ï¼Œä¾‹å¦‚ï¼š'æµ·å¤–äº¤ä»˜å·¥ç¨‹å¸ˆçš„è€ƒæ ¸ KPI æœ‰å“ªäº›ï¼Ÿ'"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with chat_container:
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            if not is_loaded:
                st.warning("å¯¹ä¸èµ·ï¼Œå‘é‡åŒ–å¼•æ“å°šæœªå‡†å¤‡å¥½ï¼Œè¯·æŸ¥çœ‹é¡µé¢ä¸Šæ–¹æç¤ºè¿›è¡Œé…ç½®ã€‚")
            else:
                with st.spinner("ğŸ” æ­£åœ¨æ£€ç´¢ Playbook ä¸åŠ¨æ€ç»éªŒåº“ç›¸å…³æ®µè½..."):
                    context_docs = rag.retrieve(prompt)
                    if not context_docs:
                        st.warning("âš ï¸ åœ¨å½“å‰çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ£€ç´¢åˆ°ä¸æ­¤é—®é¢˜å¼ºç›¸å…³çš„åŸå§‹æ®µè½ã€‚AI çš„å›ç­”å¯èƒ½ç¼ºä¹ç¡®åˆ‡ä¾æ®ã€‚")

                with st.spinner("ğŸ¤– æ­£åœ¨åŸºäºå†…éƒ¨æ–‡ä»¶æ„æ€ä¸“ä¸šå›ç­”..."):
                    response = agent.answer_playbook_question(prompt, context_docs)

                st.markdown(response)

                if context_docs:
                    with st.expander("ğŸ“ æº¯æºï¼šæŸ¥çœ‹æ£€ç´¢åˆ°çš„åŸå§‹æ–‡ä»¶æ®µè½"):
                        st.text(context_docs)

        st.session_state.messages.append({"role": "assistant", "content": response})
