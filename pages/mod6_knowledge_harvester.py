import html
import os

import requests
import streamlit as st
from bs4 import BeautifulSoup

from app_shared import get_agent
from knowledge_manager import KnowledgeManager

st.markdown('<div class="main-title">ğŸ—ï¸ çŸ¥è¯†åº“å…¨è‡ªåŠ¨æ”¶å‰²æœº (Web Auto-Harvester)</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-title">å‘Šåˆ«äººå·¥å½•å…¥ï¼åªéœ€è¾“å…¥æƒå¨æ”¿ç­–ç½‘é¡µæˆ–ç«å“æ‹›è˜ç½‘å€ï¼ŒAI çˆ¬è™«å°†è‡ªåŠ¨æå–ã€æ¸…æ´—å¹¶å°†å…¶æ²‰æ·€ä¸ºç»“æ„åŒ–çš„æœ¬åœ°çŸ¥è¯†åº“ã€‚</div>', unsafe_allow_html=True)

agent = get_agent()
km = KnowledgeManager()

col1, col2 = st.columns([1, 1])

with col1:
    st.markdown("### ğŸ•¸ï¸ æ–¹å¼ä¸€ï¼šAI ç½‘é¡µæƒ…æŠ¥è‡ªåŠ¨æŠ“å–")
    with st.form("auto_harvester_form", clear_on_submit=True):
        # æä¾›æƒå¨ä¿¡æ¯æºå¿«æ·ä¸‹æ‹‰å¡«å……
        official_urls = {
            "è‡ªå®šä¹‰è¾“å…¥ (æˆ–ç›´æ¥åœ¨ä¸‹æ–¹ç²˜è´´ URL)": "",
            "ğŸ‡¸ğŸ‡¬ æ–°åŠ å¡ EP ç­¾è¯ COMPASS è®¡åˆ†åˆ¶ (è§£æç‰ˆ)": "https://sg.acclime.com/guides/singapore-employment-pass/",
            "ğŸ‡¸ğŸ‡¬ æ–°åŠ å¡ CPF (å…¬ç§¯é‡‘) è´¹ç‡æ”¿ç­– (æ™®åæ°¸é“è§£æ)": "https://taxsummaries.pwc.com/singapore/individual/other-taxes",
            "ğŸ‡²ğŸ‡¾ é©¬æ¥è¥¿äºšæœ€æ–°åŠ³å·¥æ³•ä¿®æ­£æ¡ˆ (æ³•å¾‹è§£æ)": "https://www.taypartners.com.my/employment-act-1955-key-amendments-2023/",
            "ğŸ‡²ğŸ‡¾ é©¬æ¥è¥¿äºšå¤–ç±ä¸“æ‰ EP ç­¾è¯ç”³è¯·æŒ‡å—": "https://www.paulhypepage.my/guide/malaysia-employment-pass/",
            "ğŸ‡­ğŸ‡° é¦™æ¸¯'é«˜æ‰é€š'ä¸ä¸“æ‰ç­¾è¯å¯¹æ¯” (æ¯•é©¬å¨æŒ‡å—)": "https://www.pwccn.com/zh/services/tax/publications/tax-news-mar2024-1.html",
            "ğŸ‡­ğŸ‡° é¦™æ¸¯é›‡ä½£æ¡ä¾‹ä¸è§£é›‡è§„å®š (Deacons)": "https://www.deacons.com/zh-hant/news-and-insights/publications/employment-law-in-hong-kong-frequently-asked-questions/",
            "ğŸ‡¿ğŸ‡¦ å—éå¤–ç±å…³é”®æŠ€èƒ½ç­¾è¯ (Critical Skills) è§£æ": "https://www.xpatweb.com/south-africa-critical-skills-visa/",
            "ğŸ‡¿ğŸ‡¦ å—éè§£é›‡ä¸åŠ³åŠ¨æ³•å®åŠ¡ (Bowmans)": "https://www.bowmanslaw.com/insights/employment/south-africa-terminating-employment/"
        }

        selected_preset = st.selectbox("ğŸ’¡ å¿«é€Ÿé€‰æ‹©å®˜æ–¹ä¿¡æ¯æº (è‡ªåŠ¨å¡«å……é“¾æ¥)", list(official_urls.keys()))
        default_url = official_urls[selected_preset]

        target_url = st.text_input("ğŸ”— ç›®æ ‡ç½‘é¡µ URL", value=default_url, placeholder="æˆ–åœ¨æ­¤å¤„ç›´æ¥ç²˜è´´ä»»ä½•ç½‘é¡µé“¾æ¥...")
        region = st.selectbox("å½’å±åŒºåŸŸ", ["Singapore", "Malaysia", "South Africa", "Middle East", "Global/General"])
        category = st.selectbox("æƒ…æŠ¥åˆ†ç±»", ["å®˜æ–¹æ”¿ç­–æ³•è§„ (Official Law)", "è–ªé…¬ä¸ç«å“æƒ…æŠ¥ (Market Intel)", "ç­¾è¯ä¸å·¥ä½œè®¸å¯ (Visa/EP)", "å…¶ä»–é¿é›·æŒ‡å—"])

        submitted_url = st.form_submit_button("ğŸ¤– å¯åŠ¨çˆ¬è™«å¹¶æå–çŸ¥è¯†", type="primary")

        if submitted_url:
            if not target_url.strip() or not target_url.startswith("http"):
                st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„ç½‘é¡µé“¾æ¥ï¼ˆéœ€åŒ…å« http:// æˆ– https://ï¼‰")
            else:
                if not os.getenv("OPENAI_API_KEY"):
                    st.error("ç¼ºå¤±å¤§æ¨¡å‹ API Keyï¼Œæ— æ³•è¿›è¡Œå†…å®¹æ¸…æ´—ã€‚")
                else:
                    with st.spinner(f"æ­£åœ¨çˆ¬å– {target_url} çš„å†…å®¹..."):
                        try:
                            headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8', 'Accept-Language': 'en-US,en;q=0.5'}
                            response = requests.get(target_url, headers=headers, timeout=10, verify=True)
                            response.raise_for_status()

                            soup = BeautifulSoup(response.text, 'html.parser')
                            for script in soup(["script", "style", "nav", "footer"]):
                                script.decompose()

                            raw_text = soup.get_text(separator=' ', strip=True)

                            if len(raw_text) < 50:
                                st.error("è¯¥ç½‘é¡µä¼¼ä¹é™åˆ¶äº†çˆ¬è™«æˆ–å†…å®¹è¿‡å°‘ï¼Œæœªèƒ½æŠ“å–åˆ°æœ‰æ•ˆæ–‡æœ¬ã€‚")
                            else:
                                st.success(f"âœ… ç½‘é¡µçˆ¬å–æˆåŠŸï¼ˆå…± {len(raw_text)} å­—ç¬¦ï¼‰ã€‚æ­£åœ¨äº¤ç”± AI è¿›è¡ŒçŸ¥è¯†èƒå–...")

                                with st.spinner("ğŸ¤– AI extracting core policy intelligence..."):
                                    ai_result = agent.extract_web_knowledge(target_url, region, category, raw_text)

                                    if "EXTRACTION_FAILED" in ai_result:
                                        st.warning("AI æœªèƒ½åœ¨è¯¥ç½‘é¡µä¸­æ‰¾åˆ°æœ‰ä»·å€¼çš„æƒ…æŠ¥ã€‚")
                                    else:
                                        tags = f"{region}, Auto-Harvested, {category.split(' ')[0]}"
                                        _ok, _reason = km.add_fragment(region, category, ai_result, tags, source_url=target_url)
                                        if _ok:
                                            st.success("ğŸ‰ çŸ¥è¯†èƒå–æˆåŠŸï¼å·²è‡ªåŠ¨å­˜å…¥åº•å±‚æ•°æ®åº“ã€‚")
                                            st.info("æå–åˆ°çš„ç²¾åå†…å®¹å¦‚ä¸‹ï¼š\n" + ai_result)
                                        else:
                                            st.warning("âš ï¸ è¯¥å†…å®¹ä¸æ•°æ®åº“ä¸­å·²æœ‰æ¡ç›®å®Œå…¨ç›¸åŒï¼Œå·²è·³è¿‡ï¼ˆå»é‡ä¿æŠ¤ï¼‰ã€‚")
                        except Exception as e:
                            st.error(f"æŠ“å–ç½‘é¡µæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

    st.markdown("---")
    st.markdown("### ğŸ“ æ–¹å¼äºŒï¼šäººå·¥è¡¥å…… (å¤‡ç”¨)")
    with st.expander("ç‚¹å‡»å±•å¼€æ‰‹å·¥å½•å…¥é¢æ¿"):
        with st.form("manual_fragment_form", clear_on_submit=True):
            man_region = st.selectbox("åŒºåŸŸ", ["Singapore", "Malaysia", "South Africa", "Hong Kong", "Global/General"])
            man_category = st.selectbox("åˆ†ç±»", ["è–ªé…¬ç¦åˆ©", "ç­¾è¯ä¸åˆè§„", "æœ¬åœ°çŒå¤´æ½œè§„åˆ™"])
            man_content = st.text_area("å…·ä½“ç»éªŒ", height=100)
            if st.form_submit_button("ä¿å­˜"):
                if man_content.strip():
                    _ok, _reason = km.add_fragment(man_region, man_category, man_content, "Manual")
                    if _ok:
                        st.success("å½•å…¥æˆåŠŸ")
                    else:
                        st.warning("âš ï¸ è¯¥å†…å®¹ä¸å·²æœ‰æ¡ç›®é‡å¤ï¼Œå·²è·³è¿‡ã€‚")

with col2:
    st.markdown("### ğŸ—‚ï¸ çŸ¥è¯†åº“ç¼–è¯‘ä¸­å¿ƒ")
    st.info("æ— è®ºæ˜¯ AI ç½‘é¡µçˆ¬è™«è¿˜æ˜¯äººå·¥å½•å…¥è·å–çš„æƒ…æŠ¥ï¼Œéƒ½éœ€è¦ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®è¿›è¡Œç»Ÿä¸€ç¼–è¯‘ã€‚ç¼–è¯‘åï¼ŒRAG å¤§è„‘æ‰èƒ½è¯»å–åˆ°è¿™äº›æœ€æ–°çŸ¥è¯†ã€‚")

    if st.button("ğŸš€ ç¼–è¯‘ Playbook å¹¶åŒæ­¥è‡³ RAG å¼•æ“", type="primary", use_container_width=True):
        with st.spinner("æ­£åœ¨å°†é›¶æ•£æƒ…æŠ¥æ±‡ç¼–ä¸ºç»“æ„åŒ– Markdown åº“..."):
            success = km.compile_to_markdown()
            if success:
                from document_parser import invalidate_rag_index
                invalidate_rag_index()
                st.success("âœ… åŠ¨æ€ Playbook ç¼–è¯‘å®Œæˆï¼RAG å¼•æ“å·²è‡ªåŠ¨åˆ·æ–°ï¼Œæ–°çŸ¥è¯†ç«‹å³ç”Ÿæ•ˆã€‚")
                st.info("ğŸ’¡ ç°åœ¨å¯ç›´æ¥å‰å¾€ã€æ¨¡å—äº”ã€‘æé—®ï¼Œæ— éœ€é‡å¯ç³»ç»Ÿã€‚")
            else:
                st.warning("ç›®å‰æ•°æ®åº“ä¸­æ²¡æœ‰ä»»ä½•æƒ…æŠ¥ã€‚")

    st.markdown("---")
    fragments = km.get_all_fragments()
    if not fragments:
        st.info("çŸ¥è¯†æƒ…æŠ¥åº“ç›®å‰ä¸ºç©ºã€‚è¯·åœ¨å·¦ä¾§è¾“å…¥ç½‘å€è®© AI å»æ”¶å‰²ã€‚")
    else:
        _expired_count = sum(1 for f in fragments if km.get_expiry_status(f) == "expired")
        _soon_count = sum(1 for f in fragments if km.get_expiry_status(f) == "expiring_soon")
        if _expired_count:
            st.error(f"âš ï¸ {_expired_count} æ¡æƒ…æŠ¥å·²è¿‡æœŸï¼ˆè¶…è¿‡ 90 å¤©ï¼‰â€” å»ºè®®é‡æ–°çˆ¬å–æ›´æ–°ã€‚")
        if _soon_count:
            st.warning(f"ğŸ• {_soon_count} æ¡æƒ…æŠ¥å°†åœ¨ 14 å¤©å†…è¿‡æœŸï¼Œè¯·ç•™æ„åŠæ—¶æ›´æ–°ã€‚")
        st.write(f"å½“å‰åº“ä¸­å…±æœ‰ **{len(fragments)}** æ¡é«˜ä»·å€¼æƒ…æŠ¥ï¼š")
        with st.container(height=450):
            for f in fragments:
                _status = km.get_expiry_status(f)
                _border_color = "#DC2626" if _status == "expired" else ("#F59E0B" if _status == "expiring_soon" else "#004D99")
                _exp_label = f" Â· <span style='color:{_border_color};font-size:0.75em;'>{'âš ï¸ å·²è¿‡æœŸ' if _status == 'expired' else ('ğŸ• å³å°†è¿‡æœŸ ' + f.get('expires_at','') if _status == 'expiring_soon' else 'æœ‰æ•ˆè‡³ ' + f.get('expires_at',''))}</span>"
                st.markdown(f"""
                <div style="background-color: #FFFFFF; padding: 15px; border-radius: 6px; border: 1px solid #E2E8F0; margin-bottom: 10px; border-left: 3px solid {_border_color};">
                    <div style="display: flex; justify-content: space-between; margin-bottom: 5px;">
                        <strong>{html.escape(f['region'])} - {html.escape(f['category'])}</strong>
                        <span style="color: #6B7280; font-size: 0.8em;">{html.escape(f['date'])}{_exp_label}</span>
                    </div>
                    <p style="color: #4B5563; font-size: 0.9em; margin: 0;">{html.escape(f['content'])}</p>
                </div>
                """, unsafe_allow_html=True)
